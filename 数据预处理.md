# 太空泰坦尼克

[toc]



## 数据预处理

### 单变量分析

首先我们统计了label中0/1的个数

> Transported
> 1    4378
> 0    4315
> Name: count, dtype: int64

由此我们可以发现这个是一个平衡的数据集

其次我们还分析了其他的变量的统计个数

> HomePlanet
> Earth     0.541922
> Europa    0.250942
> Mars      0.207136
> Name: proportion, dtype: float64
>
> CryoSleep
> False    0.641694
> True     0.358306
> Name: proportion, dtype: float64
>
> Destination
> TRAPPIST-1e      0.694983
> 55 Cancri e      0.211491
> PSO J318.5-22    0.093526
>
> Name: proportion, dtype: float64
> VIP
> False    0.976561
> True     0.023439
> Name: proportion, dtype: float64

其中,我们可以发现,人们主要来自地球,木卫二和火星,有0.64的人都没有冬眠,只有0.023的人成为了VIP,目的地主要为三个.

我们还将用户所属的团队和仓位号进行了拆分处理,得到了每个人所属的团队,仓位.其中仓位的side只有2个数值,Deck只有8个数值并且大多数住在F和G.

我们还对人员的Age进行了统计得到的年龄统计值如下所示,其中0那个是缺失年龄的人的个数:<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231218221005815.png" alt="image-20231218221005815" style="zoom:50%;" />

### 分析属性与标签的关联程度

母星:

> Europa:0.658846
> Earth:0.427649
> Mars:0.523024

休眠:

> False:0.335042
> True:0.817583

目的地:

> TRAPPIST-1e:0.472199
> PSO J318.5-22:0.503769
> 55 Cancri e:0.610000

VIP:

> False:0.506475
> True:0.381910

Age:

我们将Age每10岁划分为一个属性

> 3:0.458790
> 2:0.471268
> 5:0.493716
> 1:0.532792
> 4:0.506679
> 0:0.711340
> 6:0.475962
> 7:0.434783

我们还统计了团队人数与标签的联系,好像关系不大

>1:0.452445
2:0.538050
3:0.593137
6:0.614943
4:0.640777
7:0.541126
5:0.592453
8:0.394231

Room:从图中可以看出不花钱的人更有可能被传送

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219085701338.png" alt="image-20231219085701338" style="zoom:50%;" />

Food:

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219085847143.png" alt="image-20231219085847143" style="zoom:50%;" />

Shopping:

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219085951462.png" alt="image-20231219085951462" style="zoom:50%;" />

Spa:

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219090024992.png" alt="image-20231219090024992" style="zoom:50%;" />

VR:

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219090058554.png" alt="image-20231219090058554" style="zoom:50%;" />

可以看出,VR,Spa和Room分布基本一致,Food和Shopping分布一致.

我们统计了年龄与消费之间的联系:

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219091112905.png" alt="image-20231219091112905" style="zoom:50%;" />

由图中我们发现,0\~12岁的人没有开销,所以在处理数据的时候我们对年龄0\~12之间的用户的开销全部设置为0

我们还发现休眠的人没有开销

<img src="/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231219091342970.png" alt="image-20231219091342970" style="zoom:50%;" />

我们还将仓位号拆开了,发现处于S面的人被传送的概率大于P面,且不同的仓位的传送概率不同

> B:0.734275
> F:0.439871
> A:0.496094
> G:0.516217
> E:0.357306
> D:0.433054
> C:0.680054
> T:0.200000

> P:0.451260
> S:0.555037

### 缺失值补全

所以,我们接下来对缺失的数据进行补全,我们首先将0~12岁和休眠的人的开支补全为0

其他的数字值我们使用平均数补全.非数字值使用最多的值补全



### 异常值处理

对于异常值的处理,在之前的分析中我们可以看到数据中存在部分离群点,我们使用超过0.99的最高分位数值对数据进行截断。



### 特征构建与选择

根据以上内容,我们将Food和shopping合为新变量,其他三个开销为新变量,再添加一个总开销变量.然后我们还将仓位号划分为side和deck.其次我们将每个团队的人数计算出形成新的列:



## 模型选择

### SVM

![image-20231221134052914](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231221134052914.png)

SVM算法是采用的sklearn中的库函数,调用svm.SVC()直接运行,对于SVM的输入数据,我们将string类的数据进行热编码后训练,所采用的数据列为

> ​            GroupNum,(每个组的人数)
>
> ​            HomePlanet,
>
> ​            CryoSleep,
>
> ​            CabinDeck,
>
> ​            CabinSide,
>
> ​            Destination,
>
> ​            Age,
>
> ​            VIP,
>
> ​            RoomService,
>
> ​            FoodCourt,
>
> ​            ShoppingMall,
>
> ​            Spa,
>
> ​            VRDeck,
>
> ​            NormalExpendtion,
>
> ​            LuxuryExpendtion,
>
> ​            TotalExpendtion,

### CART算法

![image-20231221140419808](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231221140419808.png)

Cart算法为手写,设置threshold大小为0.3,主要使用数据同上,但是不使用热编码

### 随机森林

![image-20231225141518676](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231225141518676.png)

随机森林使用CART作为基学习器,可以自定义基学习器的个数.对于每个基学习器,取输入的数据的`int(round(math.log(data.shape[1], 2)))`维数据进行训练,并且对数据进行随机采样.使用的数据同上

### Adaboost

Adaboost使用CART作为基学习器,相较于cart算法,Adaboost在精度上略有提升,但是效果不明显.对于带权重的样本的训练的意义模糊,当前使用的方法为自定义的带权重的Gini损失函数

![image-20231227165113146](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231227165113146.png)

### XGBoost

![image-20231225143100394](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231225143100394.png)

### GradientBoostingClassifier

![image-20231226103125635](/Users/blackcat/BJTU/Junior_winter/机器学习/MachineLearningBigWork/数据预处理.assets/image-20231226103125635.png)

